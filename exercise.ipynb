{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf4973d7",
   "metadata": {},
   "source": [
    "# Trading Data Specialist interview\n",
    "## Code test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc52a7bc",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "The purpose of the exercise is for you to showcase your ability to manipulate data and store it efficiently. \n",
    "You are expected to solve the task using python as the main language, ideally not using more than three hours of your time.\n",
    "All code is to be sent as a zip file or a github link to EDSIM@orsted.dk before your interview.\n",
    "\n",
    "\n",
    "For this case, we would like you to expose our trading data through an REST API, so it can be accessed by analysts and traders. \n",
    "The following function generates trade data. You can consider this as mocking a connection to our trading system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5178d95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_raw_data(dt_from: pd.Timestamp, dt_to: pd.Timestamp) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates (random) trade data\n",
    "    :param dt_from (pd.Timestamp): datetime from which to load the data\n",
    "    :param dt_to (pd.Timestamp): datetime up to which to load the data\n",
    "    \"\"\"\n",
    "\n",
    "    dt_from = pd.to_datetime(\"now\")\n",
    "    dt_to = dt_from + pd.to_timedelta(7, unit=\"d\")\n",
    "    n_rows = int(1e6)\n",
    "    min_price = -100\n",
    "    max_price = 300\n",
    "    min_vol = -100\n",
    "    max_vol = 100\n",
    "    cols = [\n",
    "        \"trade_id\",  # integer string identifying trade\n",
    "        \"execution_time\",  # time at which the trade was executed\n",
    "        \"price\",  # price in EUR/MWh \n",
    "        \"volume\",  # volume in MWh (negative = buy, positive = sell)\n",
    "        \"market\",  # country\n",
    "        \"product\"  # name of the product\n",
    "    ]\n",
    "    markets = [\"uk\", \"nl\", \"de\"]\n",
    "    products = [\"XBID_2h\", \"XBID_1h\", \"XBID_30min\", \"local_2h\", \"local_1h\", \"local_30min\"]\n",
    "\n",
    "    df_raw = pd.DataFrame(index=range(n_rows), columns=cols)\n",
    "    df_raw[\"product\"] = np.random.choice(products, size=n_rows)\n",
    "    df_raw[\"market\"] = np.random.choice(markets, size=n_rows)\n",
    "    df_raw[\"execution_time\"] = pd.to_datetime(\n",
    "        np.random.uniform(\n",
    "            dt_from.to_numpy(), \n",
    "            dt_to.to_numpy(), \n",
    "            size=n_rows\n",
    "        )\n",
    "    ).round(\"1ms\")\n",
    "    df_raw[\"price\"] = np.random.uniform(\n",
    "        min_price, \n",
    "        max_price, \n",
    "        size=n_rows\n",
    "    )\n",
    "    df_raw[\"volume\"] = np.random.uniform(\n",
    "        min_vol, \n",
    "        max_vol, \n",
    "        size=n_rows\n",
    "    )\n",
    "    df_raw[\"trade_id\"] = np.random.randint(n_rows, n_rows*2, size=n_rows).astype(str)\n",
    "    df_raw[\"product_duration\"] = df_raw[\"product\"].str.split(\"_\").str[-1]\n",
    "    df_raw[\"product_type\"] = df_raw[\"product\"].str.split(\"_\").str[0]\n",
    "\n",
    "    return df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d281508",
   "metadata": {},
   "source": [
    "The task is to create a data pipeline to dump the data in a batch fashion into a database. You should set up the database and the pipeline as you see fit, ideally as you would working in Azure (not mandatory). Make sure to document all your code to do that. The database setup should be optimized towards speed for the use cases described below.\n",
    "\n",
    "The data should be served from a REST API. It should be possible to extract aggregations of the trade data (price and volume) across any combination of the other columns. It should be possible to perform:\n",
    "- simple average\n",
    "- volume weighted average (using the other column as weights)\n",
    "- sum\n",
    "- minimum \n",
    "- maximum\n",
    "- average of n largest/smallest elements\n",
    "At the same time, it should be possible to track the aggregation over time (as a function of execution time, rounded to a given frequency).\n",
    "For example, the user should be able to query the development over time (e.g. every 10 minutes) of the volume weighted average price of a given type of product.\n",
    "\n",
    "\n",
    "For example, API calls could look as below. The example illustrates how a user could access the development of the minimum price per market and product type, for a product duration of 30min in the month of January, at sampling intervals of 10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60e43123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://trades.api.com?col=price&agg=min&groupby=market,product_type&product_duration=30min&from=202101010000&to=202102010000&freq=10min'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"https://trades.api.com?col=price&agg=min&groupby=market,product_type&product_duration=30min&from=202101010000&to=202102010000&freq=10min\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4266395",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
